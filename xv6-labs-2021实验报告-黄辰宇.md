# xv6-labs-2021实验报告

## 目录

[TOC]

### Lab 1: Xv6 and Unix utilities

> 本实验的主要目的是：通过实现一些基本的Unix实用程序来深入地理解xv6操作系统和C编程。

#### 1. Boot xv6 (easy)

##### 1) 实验目的

利用qemu模拟器在虚拟机上启动xv6操作系统。

##### 2) 实验步骤

1. 下载WSL

   ```bash
   wsl --install
   ```

2. 将xv6-labs-2021的代码通过git克隆到本地，进入相应的目录，并切换到相应的分支

   ```bash
   git clone git://g.csail.mit.edu/xv6-labs-2021
   cd xv6-labs-2021
   git checkout util
   ```

3. 在终端中输入以下命令来启动xv6操作系统

   ```bash
   make qemu
   ```

##### 3) 实验中遇到的问题和解决办法

无。

##### 4) 实验心得

通过这个实验，我学到了如何使用qemu模拟器来启动xv6操作系统，以及如何使用git来克隆代码、切换分支、推送修改等，对于我后续的研究非常有用。

#### 2. sleep (easy)

##### 1) 实验目的

为xv6操作系统实现这样的sleep程序：使当前进程暂停相应的时钟周期数。其中，需要暂停的时钟周期数由用户指定。

##### 2) 实验步骤

1. 在user目录下创建一个名为sleep.c的文件
2. 在sleep.c中，编写一个程序，该程序接受一个命令行参数（ticks数量），并使当前进程暂停相应的ticks数量。在该程序中，需要考虑到如果用户没有提供参数或者提供了多个参数，程序应该打印出错误信息
3. 将程序以 `$U/_sleep\` 的形式，添加到Makefile的UPROGS中
4. 使用 `make qemu` 在终端中测试运行该程序
5. 使用 `./grade-lab-util sleep` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

无

##### 4) 实验心得

通过这个实验，我学到了如何为xv6操作系统添加新用户的程序，如何处理命令行参数，以及如何使用系统调用来控制进程。这些知识对于我理解操作系统的工作原理非常有帮助。

#### 3. pingpong (easy)

##### 1) 实验目的

使用UNIX系统调用编写一个程序pingpong，在一对管道上实现两个进程之间的通信。

##### 2) 实验步骤

实验思路：创建两个管道（pipe），一个pipe负责子进程的写和父进程的读，另一个pipe负责父进程的写和子进程的读。

  1. 在user目录下创建一个名为pingpong.c的文件
  2. 在pingpong.c中，编写程序以实现功能：
     - 创建两个管道，分别负责从父到子（ping）和从子到父（pong）的通信
     - 通过 `fork()` 的返回值来分辨父子进程：返回值小于零则fork失败，此时应当报错并调用 `exit(1)` 退出程序；返回值大于零为父，则先对父到子管道调用 `write()` 发出”ping”，接着调用等待 `wait()` 等待子进程结束，随后调用 `read()` 读取子到父管道的信号”pong”；返回值为零为子，则先等待父到子管道的信号”ping”，接收到后再向子到父的管道内发出信号”pong”，退出子进程
     - 最后调用 `exit(0)` 来正常退出程序
  3. 将程序以 `$U/_pingpong\` 的形式，添加到Makefile的UPROGS中
  4. 使用 `make qemu` 在终端中测试运行该程序
  5. 使用 `./grade-lab-util pingpong` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

无

##### 4) 实验心得

通过实现pingpong程序，我深入理解了进程间通信的基本原理和使用管道进行进程通信的方法。通过使用fork、pipe和相关的系统调用函数，我成功地实现了父子进程之间的通信，并能够正确地发送和接收信号。

#### 4. primes (moderate)/(hard)

##### 1) 实验目的

使用管道编写一个primes程序，将2至35中的素数筛选并打印出来。

##### 2) 实验步骤

实验思路：将一组数输入到一个进程里，先打印出最小的一个数，这是一个素数，然后用其他剩下的数依次尝试整除这个素数，如果可以整除，则将其丢弃， 不能整除则将其通过管道传递到下一个进程中，如此循环，直到打印出所有的素数。

1. 在user目录下创建一个名为primes.c的文件

2. 在primes.c中，编写程序以实现功能，其实现原理如下图所示：

   ![Lab1-4实现原理图](E:\College\Academic Materials\大二\操作系统课程设计\实验报告图片\Lab1-4实现原理图.png)

   - 使用 `pipe(p)` 创建一个管道p，将用于存放2~35之间的所有数字

   - 在父进程当中：先关闭管道的读取端（只进行写入操作时，关闭读端可以防止意外的读操作），然后依次将34个数字写到管道p的写入端，接着关闭管道的写入端，并等待子进程结束

   - 在子进程当中：先关闭父进程的管道p的写通道，然后读取p中的第一个整数，若读取失败（p中为空），则子进程退出。

     再创建一个管道pr，并再一次分为父子进程：

     在父进程中，关闭pr的读取端，打印pr的第一个元素prime（肯定为素数）；之后，依次处理p中所有元素，若能够被prime整除，则不将其写入pr中；最后，关闭pr通道的写端，等待子进程结束。
     在子进程中：继续筛选剩下的元素，直至管道内没有元素。

3. 将程序以 `$U/_primes\` 的形式，添加到Makefile的UPROGS中

4. 使用  `make qemu`  在终端中测试运行该程序

3. 使用 `./grade-lab-util primes` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：素数筛选逻辑错误**

   在我编写primes.c的过程中，我错误地处理了素数筛选的逻辑。我没有正确地使用素数去筛选其他的数，导致输出的结果不是素数。

   **解决方案：**我重新审查了代码，并意识到我在处理素数筛选逻辑时犯了错误。在每轮筛选数时，只有当一个数不能被当前的素数整除时，我才将它写入到下一个进程的管道中。

##### 4) 实验心得

实现primes程序的过程中，我学习了如何使用管道进行进程间通信，并运用了进程的创建、关闭、读写管道等操作。通过编写筛选素数的逻辑，我深入理解了进程之间的协作和管道的作用。

#### 5. find (moderate)

##### 1) 实验目的

实现find程序，使得find程序可以遍历指定的目录及其子目录，打印出与指定模式匹配的文件名。

##### 2) 实验步骤

实验思路：用递归方式找到指定的文件夹下符合某个名字的文件，参考user/ls.c的实现方法。

1. 在user目录下创建一个名为find.c的文件
2. 在find.c中，编写程序以实现功能：
   - 在main函数中，首先检查用户是否提供了正确数量的命令行参数。如果参数数量不等于3（包括程序名），则打印错误消息并退出程序。如果参数数量正确，将第一个参数（路径）和第二个参数（要查找的文件名）传递给find函数。
   - 在find函数中，首先尝试打开给定的路径。如果无法打开，打印错误消息并返回。如果路径可以打开，使用 `fstat` 函数获取路径的状态信息。如果无法获取状态信息，关闭文件描述符，打印错误消息并返回。
   - 使用 `read` 函数读取目录中的每个条目，直到没有更多条目为止。
   - 对于每个目录条目，检查其索引节点号。如果索引节点号为0（表示条目为空），则跳过该条目。
   - 对于非空条目，将条目的名称添加到路径的末尾，形成完整的文件或子目录路径。
   - 使用 `stat` 函数获取新路径的状态信息。如果无法获取状态信息，打印错误消息并继续下一个条目。
   - 根据新路径的类型进行不同的处理：
     - 如果新路径是文件，并且文件名与要查找的文件名相同，打印文件路径。
     - 如果新路径是目录，且目录名不是"."或".."(这两个目录名分别代表当前目录和父目录)，则递归地在这个目录中查找目标文件。
   - 关闭文件描述符并返回。
3. 将程序以 `$U/_find\` 的形式，添加到Makefile的UPROGS中
4. 使用  `make qemu`  在终端中测试运行该程序
2. 使用 `./grade-lab-util find` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：错误地处理了.和..目录**

   在我编写find.c最初的实现中，我没有正确地处理**`.`**和**`..`**这两个特殊的目录名。我没有检查目录名，导致我在**`.`**和**`..`**目录中进行了递归查找。这个错误导致陷入了无限的递归，程序无法正确地运行。

   **解决方案：** 我重新审查了代码，并意识到我在处理目录时犯了错误。修改了代码，确保在处理目录时，会检查目录名。如果目录名是**`.`**或**`..`**，那么我会跳过该目录，不进行递归查找。只有当目录名既不是**`.`**也不是**`..`**时，我才进行递归查找。

2. **问题二：路径处理错误**

   在我编写find.c最初的实现中，我没有正确地处理文件和目录的路径。我忘记在目录的名称前添加斜杠，导致路径拼接错误。这个错误导致我无法正确地打开文件或子目录，我花了很多时间才找到这个问题。

   **解决方案：** 我重新审查了代码，并意识到我在处理路径时犯了错误。我修改了代码，确保在添加目录项的名称到路径的末尾时，先添加一个斜杠，然后再添加目录项的名称。此外，我还在路径的末尾添加了一个字符串结束符，以确保路径是一个正确的字符串。

##### 4) 实验心得

通过实现find程序，我学习了如何使用递归的方式遍历目录及其子目录，并使用系统调用函数获取文件和目录的信息。这个实验让我更加熟悉了文件系统的结构和相关的系统调用。

#### 6. xargs (moderate)

##### 1) 实验目的

实现xargs程序，使得此程序能够将标准输入作为参数一起输入到xargs后面的命令中。

##### 2) 实验步骤

1. 在user目录下，创建一个名为xargs.c的文件
2. 在xargs.c中，编写程序以实现功能:
   - 从标准输入读取命令和参数：程序首先从标准输入读取用户输入的命令和参数。这些输入被读取到一个字符串数组中，每个字符串代表一个参数。
   - 解析命令和参数：程序会解析用户输入的命令和参数。它会将输入的字符串分割成多个参数，每个参数都是一个独立的字符串。这个过程是通过检查空格字符来实现的，因为在命令行中，参数通常是由空格分隔的。
   - 执行命令：程序会创建一个新的进程来执行用户输入的命令。这是通过调用 `fork` 和`exec`函数来实现的。`fork` 函数会创建一个新的进程，而 `exec` 函数则会在这个新进程中执行指定的命令。
   - 等待命令执行完成：在命令开始执行后，程序会等待命令执行完成。这是通过调用 `wait` 函数来实现的。`wait` 函数会阻塞当前进程，直到子进程（也就是执行命令的进程）结束。
   - 循环处理：程序会一直重复上述步骤，直到从标准输入读取到EOF（表示输入结束）。这样，用户就可以连续输入多个命令，程序会依次执行这些命令。
3. 将程序以 `$U/_xargs\` 的形式，添加到Makefile的UPROGS中
4. 使用  `make qemu`  在终端中测试运行该程序
2. 使用 `./grade-lab-util xargs` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：参数长度限制**

    在我编写xargs.c最初的实现中，我设置了一个固定的参数长度**MAX_LEN**。然而，如果不进行设置，当输入的参数长度超过**MAX_LEN**时，这会导致参数被截断，或者在极端情况下，可能会导致缓冲区溢出。

   **解决方案：** 我重新检查了代码，并意识到我在处理参数长度时犯了错误。我修改了代码，确保在处理参数时能够正确处理参数长度超过**MAX_LEN**的情况。例如，我可以通过截断参数、显示错误消息或者拒绝执行命令等方式来处理这种情况。此外，我还需要确保**MAX_LEN**足够大，可以处理预期的最大参数长度。

##### 4) 实验心得

通过实现xargs程序，我学习了如何处理标准输入并将其作为参数传递给后续的命令。这个实验让我更加熟悉了标准输入输出的处理和进程的创建与执行。

### Lab 2: system calls

> 本实验的主要目的是：加深对操作系统的进程组织形式的了解。

#### 1. System call tracing (moderate)

##### 1) 实验目的

实现一个系统调用跟踪功能，通过创建新的系统调用，控制并跟踪特定系统调用的执行，包括进程ID、系统调用名称和返回值，以便于后续的调试工作。

##### 2) 实验步骤

1. 首先切换到相应的分支：

      ```bash
      git fetch
      git checkout syscall
      make clean
      ```

2. 根据给出的提示修改相应的文件：

   - 在Makefile中添加 `$U/_trace\` 到UPROGS，但此时系统调用的用户空间存根尚不存在
   - 在user/user.h中添加 `int trace(int);` 声明trace的系统调用的原型
   - 在user/usys.pl中添加存根 `entry("trace");` 
   - 在kernel/syscall.h中添加系统调用号 `#define SYS_trace 22` 

3. 在kernel/sysproc.c中添加一个sys_trace()函数，通过在proc结构中记住其参数来实现新的系统调用：

   - 在kernel/sysproc.c中，定义sys_trace()函数，将输入的掩码传递到proc的trace_mask中
   - 在kernel/syscall.c中，仿照其他系统调用，增添 `extern uint64 sys_trace(void);` 和 `[SYS_trace]  sys_trace,` ；在syscall()中，取得掩码，获得其对应的系统调用名称，将其打印出来。

4. 在kernel/proc.c中，修改fork()以从父进程复制跟踪掩码到子进程

5. 使用  `make qemu`  在终端中测试运行该程序

6. 使用 `./grade-lab-syscall trace` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：参数传递问题**

   在sysproc.c中可以仿照 `sys_exit` 函数的方式使用 `argint(0, &n)` 拿到输入进来的mask，但mask对应的系统调用是在syscall.c中才被调用，应该如何传递mask，以实现trace的功能？

   **解决方案**：有两种方式：全局变量共享内存、信号量传递。后者通过形参的方式传递，在此处不太可行。查看syscall的代码，发现参数是从`proc`里面来获得的，`proc`是进程控制块，在sysproc中也有如sys_sbrk等函数调用到`myproc`。故最终通过进程进行通信，设置了`proc->trace_mask`来标记输入进来的掩码，实现参数传递。此外，也需要到proc.h中去修改`struct proc`的变量，引入 `int trace_mask` 。

##### 4) 实验心得

通过这次实验，我深入理解了系统调用的工作原理，并学习了如何添加新的系统调用。我发现，系统调用是操作系统提供给用户程序的接口，它是用户程序与操作系统内核进行交互的关键机制。在实验过程中，我遇到了一些问题，但通过查阅资料和不断尝试，我成功解决了这些问题，提高了我的问题解决能力。

#### 2. Sysinfo (moderate)

##### 1) 实验目的

添加一个新的系统调用sysinfo，它可以收集和返回关于正在运行的系统的信息（需要获取当前空闲的内存大小填入struct sysinfo.freemem中，获取当前所有不是UNUSED的进程数量填入struct sysinfo.nproc中。）

##### 2) 实验步骤

1. 根据给出的提示修改相应的文件：
2. 参考kernel/sysfile.c中的 `sys_fstat()` 与kernel/file.c中的`filestat()`使用 `copyout()`来编写kernel/sysproc.c中的`sys_sysinfo()`函数。参考kernel/kalloc.c与 kernel/proc.c来获得对应的info参数
3. 使用  `make qemu`  在终端中测试运行该程序
2. 使用 `./grade-lab-syscall sysinfo` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：提示中给出的操作的用途**

   在Lab2的两个实验中，hints都需要修改一系列文件，但其用途暂未清晰。

   **解决方案**：回顾课程内容，了解各个文件的作用。经过整理后，理解如下：

      1. 在Makefile中添加`$U/_sysinfotest\`到UPROGS，这是为了让编译系统知道需要编译和链接`sysinfotest`这个用户程序。
      2. 在user/user.h中添加`int sysinfo(struct sysinfo*);`，这是为了在用户空间提供`sysinfo`系统调用的接口。在这之前声明结构体`struct sysinfo;`是因为`sysinfo`系统调用需要这个结构体类型的参数。
      3. 在user/usys.pl中添加存根`entry("sysinfo");`，这是为了生成用户空间的系统调用存根，这个存根会在用户程序调用`sysinfo`时转到内核空间的实现。
      4. 在kernel/syscall.h中添加系统调用号`#define SYS_sysinfo 23`，这是为了给`sysinfo`系统调用分配一个唯一的编号。
      5. 在kernel/syscall.c中，增添`extern uint64 sys_trace(void);`与`[SYS_sysinfo] sys_sysinfo`，这是为了在系统调用分派函数中添加`sysinfo`的入口。
      6. 参考kernel/sysfile.c中的 `sys_fstat()` 与kernel/file.c中的`filestat()`使用 `copyout()`来编写kernel/sysproc.c中的`sys_sysinfo()`函数。这是因为`sysinfo`系统调用需要将内核空间的信息复制到用户空间，`copyout`函数正是用于这个目的。
      7. 参考kernel/kalloc.c与 kernel/proc.c来获得对应的info参数，这是因为`kalloc.c`中实现了物理页面的分配和释放，可以提供系统当前的内存使用情况；而`proc.c`则负责进程的创建、调度和销毁，可以提供系统当前的进程数量和CPU使用情况。这些信息被收集并填充到`sysinfo`结构体中，然后通过`sys_sysinfo`系统调用返回给用户空间。

##### 4) 实验心得

在这次实验中，我学习了如何在xv6操作系统中添加一个新的系统调用。这个过程包括了在用户空间和内核空间之间建立连接，以及如何在内核中实现这个系统调用的功能。这个过程让我更深入地理解了操作系统的工作原理，特别是系统调用的工作机制。

### Lab 3: page tables

> 本实验的主要目的是：探索页表，修改页表以简化从用户态拷贝数据到内核态的方法。

#### 1. Speed up system calls (easy)

##### 1) 实验目的

一些操作系统（例如 Linux）通过在用户空间和内核之间共享只读区域的数据来加速某些系统调用。这消除了执行这些系统调用时进行内核交叉的需要。本实验是为 xv6 的 getpid() 系统调用实现这种优化，进而加速系统调用。

##### 2) 实验步骤

1. 首先切换到相应的分支：

   ```bash
   git fetch
   git checkout pgtbl
   make clean
   ```

2. 根据给出的提示编写程序：

   - 在kernel/proc.c中的`proc_pagetable()`中添加虚拟页的映射关系：（仿照将trapframe映射到TRAMPOLINE的方式来写）：
     - 在proc.h中添加USYSCALL的结构体： `struct usyscall *usyscall;`
       - 使用`mappages()`函数，将usyscall结构映射到用户空间的USYSCALL地址处，映射的页面大小为PGSIZE，允许读和访问
       - 执行失败时，将USYSCALL、TRAMPOLINE从页表中删去并释放。
   - 在`allocproc()`函数中为页面进行初始化：（参考trapframe的代码）
     - 使用`kalloc()`分配一个usyscall页面到进程p中；
     - 将usyscall页面的pid定义为进程的pid；
     - 处理请求页面失败的情况：使用`freeproc(p)`来释放进程p占用的资源，然后释放进程的锁，并返回0表示失败。
   - 确保在`freeproc()`中释放页面：（参考trapframe的代码）
     - 在`freeproc()`中若指针不为空（即为有usyscall），则使用`kfree()`来释放资源，并将该指针指向0（NULL）；

     - 在`freeproc()`所调用的用于释放页面的子函数`proc_freepagetable()`中使用`uvmunmap()`来移除USYSCALL的映射关系。

5. 使用  `make qemu`  在终端中测试运行该程序

6. 使用 `./grade-lab-pgtbl ` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：访问一个没有权限的地址**

   在测试时，进程遇到了一个意外的陷阱，具体的陷阱类型是由`scause`字段给出的。在这种情况下，scause的值是0x000000000000000d，这通常表示进程试图访问一个它没有权限访问的内存地址。`sepc`字段给出的是发生陷阱时的程序计数器值，也就是发生错误的指令的地址。`stval`字段给出的是触发陷阱的异常地址或异常指令。

   **解决方案**：寻找与权限相关的自己写的代码，发现是在`mappages()`建立USYSCALL与TRAMPOLINE的联系时，使用了PTE权限，一开始照搬TRAPFRAME与TRAMPOLINE写成了`PTE_R | PTE_W`。又根据提示，此处的权限应该为`PTE_R | PTE_U`，修正后运行正确。

##### 4) 实验心得

通过本次实验，我了解了操作系统如何通过在用户空间和内核之间共享只读区域的数据来加速某些系统调用的过程。我学习了如何在xv6的getpid()系统调用中实现这种优化，以加速系统调用。我也了解了内存的布局方式，如何在内核中添加新的内存映射，以及如何处理内存映射失败的情况。

总的来说，这次实验让我对操作系统的内存管理有了更深入的理解，也让我更熟悉了xv6操作系统的内部工作机制。

#### 2. Print a page table (easy)

##### 1) 实验目的

为了帮助我们更好地理解RISC-V的页表，我们将编写一个函数来打印页表的内容，实现页表可视化，这将有助于我们对页表的理解和未来的调试工作。

##### 2) 实验步骤

1. 在kernel/vm.c中定义函数`vmprint()`接受一个`pagetable_t`参数，并按照格式打印页表：
   
   - 在defs.h中声明`void vmprint(pagetable_t pagetable);`，这样可以在exec.c中调用此函数
   
   - 在kernel/vm.c中实现`vmprint()`函数（参考`freewalk()`函数，递归实现`printwalk()`）
   
2. 将`if(p->pid==1) vmprint(p->pagetable)`复制到exec.c的`exec()`中的`return argc;`之前，以实现打印第一个进程（shell程序）的页表。

3. 使用  `make qemu`  在终端中测试运行该程序

4. 使用 `./grade-lab-pgtbl ` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

无

##### 4) 实验心得

在这个实验中，我学习了如何在xv6操作系统中实现页表的可视化。这个过程涉及到了对页表的深入理解，包括页表条目（PTE）的结构，页表的层级结构，以及如何通过页表进行地址转换。我也学习了如何在C语言中使用递归来遍历页表的所有条目，并打印出它们的信息。

这个实验让我对页表有了更深入的理解，也让我更熟悉了C语言的递归和打印操作。这将对我未来在操作系统或其他编程中的学习和工作有所帮助。

#### 3. Detecting which pages have been accessed (hard)

##### 1) 实验目的

某些自动内存管理机制，如垃圾收集器，可以从页面访问信息中受益。在这部分实验中，我们将通过检查RISC-V页表中的访问位，向用户空间报告哪些页面已被访问。

##### 2) 实验步骤

1. 阅读user/pgtlbtest.c中的`pgaccess_test()`函数，了解`pgaccess`系统调用的使用方式（`pgaccess(起始地址,查找页数,位图地址)`）

2. 在kernel/sysproc.c中实现`sys_pgaccess()`函数（这个函数将会被用户程序通过系统调用来调用）：
   
   - 使用`argaddr()`和`argint()`函数接收到的系统调用的参数
   
   - 为查找页数设置上限32
   
   - 循环下面过程，直到bitmask被填充完成：
   
     - 在kernel/riscv.h中加上PTE_A的定义：`#define PTE_A (1L << 6)`
   
     - 参考 `kernel/vm.c` 中的`walk()`来正确查找到PTE
   
     - 检查PTE的访问位（PTE_A）。如果访问位被设置，说明该页面已经被访问过
   
     - 清除访问位
   
   - 输出bitmask：对于输出的位掩码，可以先在内核中创建一个临时缓冲区，在填充完相关的位信息后，再通过`copyout()`函数将其复制到用户空间。
   
   - 最后，如果所有操作都成功，函数返回0。如果有任何错误（例如参数解析失败，或者复制到用户空间失败），函数返回-1。
   
3. 使用  `make qemu`  在终端中测试运行该程序

4. 使用 `./grade-lab-pgtbl ` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：标志位的定义问题**

   **解决方案**：参考RISC-V架构手册和课本中的内容，我们可以确定`PTE_A`（访问位）的位置应在页表条目（PTE）的第6位。在RISC-V架构中，页表条目（PTE）的每一位都有特定的含义，这些位被定义为`PTE_*`。例如，`PTE_W`表示该页是否允许写操作，`PTE_V`表示该页是否有效。同样，`PTE_A`表示该页是否被访问过。这些位的设置和查询对于页表的管理和虚拟内存的操作至关重要。

##### 4) 实验心得

这次的实验让我对操作系统中的内存管理有了更深入的理解，特别是对于页表管理和虚拟内存的操作。通过实现`pgaccess()`系统调用，我了解到了如何通过检查RISC-V页表中的访问位来报告哪些页面已被访问。这个过程中，我学习到了如何使用`walk()`函数来查找正确的页表条目（PTE），以及如何通过位运算来清除和设置PTE的访问位。

总的来说，这次的实验不仅提高了我的编程技能，也加深了我对操作系统中内存管理的理解。我期待着在未来的学习中，能够更深入地探索这些知识。

### Lab 4: traps

> 当xv6系统中出现中断、异常、系统调用三种情况时都会执行陷入机制，陷入到内核态执行一系列操作。本实验的主要目的是学习trap机制，以及如何在trap中实现系统调用。

#### 1. RISC-V assembly (easy)

##### 1) 实验目的

通过阅读xv6仓库中的user/call.c文件，理解RISC-V汇编的基本概念。

##### 2) 实验步骤

1. 首先切换到相应的分支：

   ```bash
   git fetch
   git checkout traps
   make clean
   ```

2. 在xv6的命令行中输入运行`make fs.img`，编译user/call.c程序，得到可读性比较强的user/call.asm文件

3. 阅读生成的user/call.asm中函数`g`,`f`,`main`实现的汇编代码，并回答问题：

   1. **Which registers contain arguments to functions? For example, which register holds 13 in main's call to `printf`?**

      函数参数存储在寄存器a0~a7中，例如main函数的`printf`中的13寄存在a2寄存器中。

   2. **Where is the call to function `f` in the assembly code for main? Where is the call to `g`? (Hint: the compiler may inline functions.)**

      没有这样的代码。 `g`被内联inline到 f(x) 中，然后 `f`又被进一步内联到 `main`中。

   3. **At what address is the function `printf` located?**

      0x0000000000000628, main 中使用 pc 相对寻址来计算得到这个地址。

   4. **What value is in the register `ra` just after the `jalr` to `printf` in `main`?**

      0x0000000000000038, jalr 指令的下一条汇编指令的地址。

   5. **Run the following code.**

      ```C
      	unsigned int i = 0x00646c72;
      	printf("H%x Wo%s", 57616, &i);
      ```
   
      **What is the output?**

      **The output depends on that fact that the RISC-V is little-endian. If the RISC-V were instead big-endian what would you set to in order to yield the same output? Would you need to change to a different value?`**

      `HE110 World`；

      需要将`unsigned int i = 0x00646c72;`替换成`unsigned int i = 0x00726c64;`

      不需要，57616 的十六进制是 110，无论端序（十六进制和内存中的表示不是同个概念）

   6. **In the following code, what is going to be printed after ? (note: the answer is not a specific value.) Why does this happen? `'y='`**

      ```C
      	printf("x=%d y=%d", 3);
      ```

      输出的是一个受调用前的代码影响的“随机”的值。因为 printf 尝试读的参数数量比提供的参数数量多。 第二个参数 `3` 通过 a1 传递，而第三个参数对应的寄存器 a2 在调用前不会被设置为任何具体的值，而是会包含调用发生前的任何已经在里面的值。

##### 3) 实验中遇到的问题和解决办法

1. **问题一：通过调试查看对应参数**

    **解决方案**：查阅教程发现可以通过gdb来调试，获得对应的值，相应操作如下：

      ```bash
      make CPU=1 qemu-gdb
      # 新开一个终端
      gdb-multiarch kernel/kernel
      # 进入gdb后执行
      (gdb) set confirm off
      (gdb) set architecture riscv:rv64
      (gdb) set riscv use-compressed-breakpoints yes
      (gdb) target remote localhost:25000
      ```

      接下来，进入调试过程。在调试过程中，通常会使用以下操作：

      - `layout split`：view src-code & asm-code
      - `file xxx`： 调试特定（用户空间）的文件（如`file user/_call`）
      - `b xxx`：在`xxx`处添加断点（如`b main`、`b *0x34`）
      - `c`：继续执行程序，直到遇到下一个断点
      - `s`：单步执行程序源码，如果当前行有函数调用，会进入该函数（`si`为执行汇编）
      - `n`：单步执行程序源码，但在遇到函数调用时不会进入该函数（`ni`为执行汇编）
      - `d`：删除所有的断点
      - `p xxx`：打印对应硬件中的值
        - `p $a0` # 打印a0寄存器的值
        - `p/x 1536` # 以16进制的格式打印1536
      - `i xxx`：查看`xxx`的信息
        - `i r a0` # info registers a0
        - `x/i 0x630` # 查看0x630地址处的指令
        - `x/g 0x80000000` # 查看0x80000000地址处的值（g表示值的长度有64位）

##### 4) 实验心得

通过这次实验，我对RISC-V汇编有了更深入的理解，特别是函数调用和参数传递的过程。我了解到函数参数是通过寄存器传递的，这是因为寄存器的访问速度比内存快得多，所以在函数调用中使用寄存器来传递参数可以提高程序的运行速度。此外，我还了解到了函数调用的过程中，如何保存和恢复调用者的环境，这是通过使用ra寄存器和栈来实现的。

此外，我还了解到了一些关于编译器优化的知识。例如，编译器可能会将一些简单的函数内联到调用它的函数中，以减少函数调用的开销。这在我查看汇编代码时给我带来了一些困扰，因为我没有找到我期望看到的函数调用。但是通过查阅资料和进行实验，我理解了这是编译器为了优化程序性能做的改变。

总的来说，这次实验让我对汇编语言和函数调用有了更深入的理解，也让我对编译器的工作原理有了更深的理解。虽然过程中遇到了一些困难，但是通过解决这些困难，我收获了很多知识和经验。

#### 2. Backtrace (moderate)

##### 1) 实验目的

在kernel/printf.c中实现一个backtrace()函数，该函数能够打印出当前调用栈上的函数调用列表。

##### 2) 实验步骤

1. 将`void  backtrace(void);`添加到def.h中声明函数

2. 向sysproc.c的sys_sleep函数返回之前加入`backtrace()`函数

3. 在kernel/riscv.h中加入提示中函数，以便`backtrace()`能返回当前页指针

4. 在kernel/printf.c中实现`backtrace()`函数

5. 使用`make qemu`，在qemu环境中使用`bttest`得到返回地址
6. 退出qemu，在终端运行`addr2line -e kernel/kernel`，从上面的地址中粘贴地址，得到的结果所对应的代码位置应该就是该函数的返回值位置
7. 将`backtrace()`加到kernel/printf.c中的`panic(`)函数中，应用程序崩溃了就可以把他的调用关系打印出来

##### 3) 实验中遇到的问题和解决办法

1. **问题一：函数调用栈相关知识**

   **解决方案**：查阅相关资料后总结如下：

   1. **函数调用栈（Stack）**
      - 由高地址往低地址增长；
      - 在xv6里，有一页大小（4KB）；
      - 栈指针（stack pointer）保存在sp寄存器里
   1. **栈帧（Stack Frame）**
         - 当前栈帧的地址保存在 s0/fp寄存器里
         - 当前栈帧的地址也叫栈帧的指针（frame pointer， fp），指向该栈帧的最高处
         - 栈帧指针往下偏移8个字节是函数返回地址 return address，往下偏移16个字节是上一个栈帧的栈帧指针（previous frame pointer）
      - sp是stack pointer，用于指向栈顶（低地址），保存在寄存器中;fp是frame pointer，用于指向当前帧底部（高地址），保存在寄存器中，同时每个函数栈帧中保存了调用当前函数的函数（父函数）的fp（保存在to prev frame那一栏中）；这些栈帧都是由编译器编译生成的汇编文件生成的。

##### 4) 实验心得

通过这次实验，我对函数调用栈和栈帧有了更深入的理解。我了解到函数调用栈是程序运行时用来保存函数调用关系的一种数据结构，每次函数调用时都会在栈上创建一个新的栈帧，用来保存函数的局部变量和返回地址等信息。当函数返回时，对应的栈帧会被销毁，函数的返回地址会被取出来，用来恢复调用者的执行环境。

此外，我还了解到了如何使用栈帧指针和返回地址来实现函数的回溯。这是通过在每个栈帧中保存上一个栈帧的栈帧指针和当前函数的返回地址来实现的。通过这种方式，我们可以从任何一个栈帧开始，沿着栈帧指针一直回溯到最初的函数调用。

总的来说，这次实验让我对函数调用栈和栈帧有了更深入的理解，也让我对函数回溯有了更深的理解。虽然过程中遇到了一些困难，但是通过解决这些困难，我收获了很多知识和经验。

#### 3. Alarm (hard)

##### 1) 实验目的

向xv6添加一个功能，该功能可以周期性地提醒一个进程它正在使用CPU时间。这对于想要限制自己消耗的CPU时间的计算绑定进程，或者想要进行计算但也想要定期执行某些操作的进程非常有用。

##### 2) 实验步骤

1. 修改Makefile，在UPROGS中加入`$U/_alarmtest\`
2. 在user/user.h里添加`sigalarm`和`sigreturn`的函数声明

3. 同Lab2分别添加其他部分：
   - 在user/usys.pl中添加存根`entry("sigalarm");`与`entry("sigreturn");`

   - 在kernel/syscall.h中添加系统调用号

   - 在kernel/syscall.c中，增添`extern uint64 sys_sigalarm(void);`、`extern uint64 sys_sys_sigreturn(void);`与`[SYS_sigalarm] sys_sigalarm`、`[SYS_sigreturn] sys_sigreturn`；
4. 需要让`sys_sigalarm`记录时钟间隔，为此，在kernel/proc.h的`proc()`中增添相关属性，并在kernel/proc.c的`allocproc()`中初始化这些属性
5. 在kernel/trap.c的`usertrap()`里的`if(which_dev == 2)`分支中处理中断，寻找中断时RISC-V上决定用户空间代码恢复执行的指令地址的地方（`p->trapframe->epc`），将其改为handler
6. 在kernel/sysproc.c中实现两个系统调用函数`sys_sigalarm()`与`sys_sigreturn()`
7. 完成之后，一旦通过`test0`、`test1`和`test2`，就运行`usertests`以确保没有破坏内核的任何其他部分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：实现信号处理机制**

   在实验中需要实现一个基本的信号处理机制，即当定时器到达设定的时间间隔时，调用一个预先设定的处理函数。然而，如何正确地设置定时器和处理函数，以及在信号处理函数执行完毕后如何恢复进程的执行状态，是个难题。

   **解决方案**：理解并使用系统调用以及内存拷贝函数：

      1. 首先，理解并实现`sys_sigalarm`系统调用。这个系统调用用于设置一个定时器，当定时器到达设定的时间间隔时，会调用一个预先设定的处理函数。这个函数有两个参数，第一个参数是定时器的时间间隔，第二个参数是定时器到时需要调用的处理函数的地址。

      2. 其次，理解并实现`sys_sigreturn`系统调用。这个系统调用在信号处理函数执行完毕后，恢复进程的执行状态。它会将进程的`trapframe`（保存进程执行状态的结构体）恢复为信号发生前的状态。在这个函数中，使用了`memmove`函数进行内存拷贝（`void *memmove(void *dest, const void *src, size_t n);`），将`alarm_trapframe`（保存信号处理函数执行前的进程状态）的内容拷贝到`trapframe`（保存当前进程状态），从而恢复进程的执行状态。
      3. 最后，通过实验和代码调试，确保系统调用的正确性，并确保在信号处理函数执行完毕后，进程的执行状态能够正确恢复。

##### 4) 实验心得

在这次实验中，我深入理解了操作系统中的信号处理机制，以及如何在xv6系统中实现这一机制。我学习了如何使用系统调用来设置定时器和处理函数，以及如何在信号处理函数执行完毕后恢复进程的执行状态。这个过程中，我对系统调用的工作原理有了更深入的理解，也学习了如何使用内存拷贝函数来保存和恢复进程的状态。

总的来说，这次实验让我对操作系统的工作原理有了更深入的理解，也提高了我的编程和调试技能。我期待在未来的实验中继续学习和探索。

### Lab 5: Copy-on-Write Fork for xv6

> 本实验的主要目的：实现写时拷贝机制（Copy-on-Write，简称COW）。

#### 1. Implement copy-on write (hard)

##### 1) 实验目的

实现写时拷贝（Copy-on-Write，简称COW）的`fork()`。COW的fork()通过推迟分配和复制物理内存页面，直到实际需要复制的时候，从而提高了内存使用效率和系统性能。

##### 2) 实验步骤

1. 首先切换到相应的分支：

   ```bash
   git fetch
   git checkout cow
   make clean
   ```

2. 在kernel/riscv.h中定义`PTE_COW`，表示RISC-V中的RSW（reserved for software）位。这是为了在页表项中标记哪些页是COW页：`#define PTE_COW (1L << 8)` 

3. 在kernel/kalloc.c中执行以下操作：

      - 定义`INDEX`宏，用于将物理地址转换为引用计数数组的索引:

        ```c
        #define INDEX(pa) (((char*)pa - (char*)PGROUNDUP((uint64)end)) >> 12)
        ```

      - 修改`kmem`结构，增加一个用于记录每个物理页引用计数的数组`ref_count`，增加一把锁`ref_lock`。

      - 修改`kinit()`函数，使其在初始化物理内存的同时，也初始化引用计数数组和锁。

      - 修改`freerange()`函数，使其在将物理页添加到空闲列表时，也初始化相应页的引用计数：`kmem.ref_count[INDEX((void*)p)] = 1;`

      - 修改`kfree()`函数，使其在释放物理页时，先减少相应页的引用计数，只有当引用计数为0时，才真正将页放回到空闲列表。

      - 修改`kalloc()`函数，使其在分配物理页时，将相应页的引用计数设置为1。

4. 在kernel/defs.h中声明并在kernel/kalloc.c中实现一些操作引用计数的函数`get_kmem_ref()`、`add_kmem_ref()`。这些函数的目的是抽象引用计数的相关操作，使代码更清晰。

5. 修改kernel/vm.c中的`uvmcopy()`函数，使其在复制页表时不再复制物理页，而是让子进程共享父进程的物理页（使用`mappages()`进行映射），并增加相应页的引用计数。同时，将这些页的写权限去掉，标记为COW页。

6. 修改kernel/trap.c中的`usertrap()`函数，使其能处理写页错误。

      - 当一个COW页发生写页错误（`r_scause() == 15`）时，为其`kalloc()`分配一个新的物理页，并将旧页的内容复制到新页中`memmove()`，然后将新页`mappages()`安装到页表中，并设置写权限`PTE_W`，最后`kfree()`释放旧页面。
      - 为了实现其功能，还需要修改kernel/vm.c中的`mappages()`函数，使其在映射已经映射过的页时不再panic。

7. 修改kernel/vm.c中的`copyout()`函数，使其在遇到COW页时，也能处理写页错误。（具体方法与`usertrap()`类似）

8. 最后，在终端输入.`/grade-lab-cow`以获得最终得分。

##### 3) 实验中遇到的问题和解决办法

1. **问题一：将物理地址转换为引用计数数组的索引**

   **解决方案**：`(char*)pa - (char*)PGROUNDUP((uint64)end)`计算的是物理地址`pa`与内核空间结束地址`end`之间的偏移量，然后右移12位（即除以4096，物理页的大小为4KB）得到的结果就是该物理地址对应的页号。最终通过宏来计算更方便。

2. **问题二：处理写页错误**

   **解决方案**：查阅相关资料、借鉴他人做法，将实现方式总结如下：

      1. 获取引发错误的虚拟地址`va`并将其向下舍入到最近的页边界。
      2. 使用`walk`函数获取该虚拟地址对应的页表项（PTE）。
      3. 检查该PTE是否有效，是否设置了`PTE_COW`位（标记页面是否为COW页面），以及是否允许用户访问。如果任一条件不满足，终止进程。
      4. 获取该PTE对应的物理地址`pa`，并获取该物理页面的引用计数`ref`。
      5. 如果，将该页面设置为可写，并清除`PTE_COW`位。
      6. 如果引用计数大于1，分配新的物理页面，将旧页面内容复制到新页面，将新页面映射到引发错误的虚拟地址，设置`PTE_W`位并清除`PTE_COW`位，然后释放旧页面。（这样，当前进程就可以写入新页面，而不会影响到其他进程）

##### 4) 实验心得

通过本次实验，我深入理解了写时复制（Copy-on-Write，简称COW）的fork()的工作原理和实现方法。COW的fork()通过推迟分配和复制物理内存页面，直到实际需要复制的时候，从而提高了内存使用效率和系统性能。并且，我对虚拟内存管理有了更深的理解，包括页表、物理页、虚拟地址和物理地址的关系等。

### Lab 6: Multithreading

> 本实验与多线程有关，具体包括：在用户级线程包中实现线程之间的切换，使用多个线程来加速程序，并实现一个屏障。

#### 1. Uthread: switching between threads (moderate)

##### 1) 实验目的

熟悉多线程编程，为用户级线程系统设计上下文切换机制。

##### 2) 实验步骤

1. 首先切换到相应的分支：

      ```bash
      git fetch
      git checkout thread
      make clean
      ```

2. 在user/uthread_switch.S中加入汇编代码

3. 在user/uthread.c中修改以下内容：

    - 定义一个结构体`tcontext`，用于保存寄存器内容，并将其加入到`thread`结构体中（命名为`context`），这样每个线程都有自己的上下文，可以在切换线程时保存和恢复。
    - 补全函数`thread_create()`，实现找到空闲位置、设置接下来要跑的线程栈以及运行起始位置、然后切换线程。
    - 补全函数`thread_schedule()`，根据提示调用`thread_switch()`

4. 使用  `make qemu`  在终端中测试运行该程序

2. 使用 `./grade-lab-thread` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：进程上下文切换的实现**

   **解决方案**：跟随教程，查阅源码：

   1. kernel/trap.c中的`usertrap`函数是用于将用户空间切换到内核空间，会保存用户空间的32个寄存器然后切换至内核空间中来，用于查看是否是由于时钟中断导致的，如果是则调用`yield()`函数处理，将CPU资源给让渡出来。（在`kerneltrap`中也有使用）

   2. 参考kernel/proc.c中`yield`函数的实现过程，将进程状态设置为可执行（`RUNNABLE`），下次在调度时可以将其执行，后调用`sched`函数。

   3. 参考kernel/proc.c中`sched`函数的实现过程，在判断是否符合上下文切换的条件后处理中断，后调用`swtch`函数进行上下文切换。

   4. 参考kernel/swtch.S中`switch`函数的实现过程，将当前的14个callee register全部放到a0以及其偏移量上，再将a1上的内容全部放到14个callee register上。（不同于trap中保存和回复现场需要保存/恢复32个寄存器）

      对于问题“为什么RISC-V中有32个寄存器，但是swtch函数中只保存并恢复了14个寄存器？"回答如下：

      这个问题涉及到RISC-V架构下的寄存器使用规则和函数调用规约（calling conventions）。在RISC-V中，有32个寄存器，但并非所有的寄存器都需要在函数调用时保存。RISC-V的函数调用规约将这些寄存器分为两种类型：Callee Saved Register和Caller Saved Register。

      1. Callee Saved Register（被调用者保存的寄存器）：当一个函数（被调用者）准备使用这些寄存器时，它需要首先保存这些寄存器的原始值，以便在函数返回时可以恢复这些值。这样做是为了保护调用者函数的执行环境。
      2. Caller Saved Register（调用者保存的寄存器）：**调用者在调用其他函数（被调用者）之前，如果希望这些寄存器的值在函数调用后仍然保持，那么它需要先保存这些寄存器的值。**这样做是因为被调用的函数可能会改变这些寄存器的值。

      swtch函数只保存并恢复了14个寄存器，这些寄存器应该就是被定义为Callee Saved Register的寄存器。其他寄存器（Caller Saved Register）的保存和恢复则是由swtch函数的调用者来完成的。在函数调用中，swtch函数只需要关心Callee Saved Register，因为这部分是swtch函数需要负责保存和恢复的。而Caller Saved Register的保存和恢复则是由swtch函数的调用者来负责的，因为它们可能在swtch函数执行过程中被修改。

   5. 运行完成之后，调试时发现其到`scheduler`调度器中运行，调度策略：**时间片轮转调度**，使用`swtch`来实现上下文切换。

##### 4) 实验心得

在进行这个实验的过程中，我对多线程编程以及用户级线程系统的设计有了深入的理解，特别是如何设计线程的上下文切换机制。通过这个实验，我也对堆栈的增长方向有了更直观的认识，理解了为什么在大多数现代操作系统中，堆栈是从高位向低位增长的，以及这种设计的好处。

总的来说，这是一个非常有价值的实验，它帮助我理解了线程的上下文切换是如何工作的，也让我对多线程编程有了更深的理解和实践经验。我相信这个实验对我的编程技能和计算机系统知识都有很大的提升。

#### 2. Using threads (moderate)

##### 1) 实验目的

探索使用线程和锁的并行编程。将使用一个哈希表。需要在一个真实的Linux或MacOS计算机上完成这个任务，这台计算机需要有多个核心。这个任务使用UNIX pthread线程库。需要修改哈希表，使其在多线程使用时仍然正确。

##### 2) 实验步骤

1. 在notxv6/ph.c中进行如下修改：

   - 声明锁：`pthread_mutex_t lock[NBUCKET];`

   - 在main里初始化锁：

     ```C
      for (int i = 0; i < NBUCKET; i++)
         pthread_mutex_init(&lk[i],NULL);
     ```

   - 在`put()`与`get()`中上锁（`pthread_mutex_lock(&lock[i]);`）与开锁（`pthread_mutex_unlock(&lock[i]);`）

2. 使用  `make qemu`  在终端中测试运行该程序

3. 使用 `./grade-lab-thread` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

无

##### 4) 实验心得

在这个实验中，我深入学习了如何使用线程和锁进行并行编程，提高了我在实际项目中应用并行编程的能力，同时激发了我对并行编程和多核系统的进一步学习的兴趣。

#### 3. Barrier (moderate)

##### 1) 实验目的

实现一个屏障：一个应用程序中的点，所有参与的线程必须等待所有其他参与的线程也到达那个点。将使用pthread条件变量，这是一种类似于xv6的sleep和wakeup的序列协调技术。需要在一个真实的计算机上完成这个任务。目标是实现所需的屏障行为。需要在put和get中插入锁和解锁语句，以使两个线程的键丢失数量始终为0。

##### 2) 实验步骤

1. 在notxv6/barrier.c中按照要求补充完成`barrier()`函数，其步骤可以分解如下：

   1. **获取互斥锁**：通过`pthread_mutex_lock(&bstate.barrier_mutex);`获取互斥锁，以保护共享资源`bstate`的访问。

   2. **增加线程计数**：通过`bstate.nthread++;`增加线程计数，表示有一个新的线程已经到达了屏障。

   3. **检查是否所有线程都已到达屏障**：通过`if (bstate.nthread < nthread)`检查是否所有线程都已到达屏障。
      - 如果还有线程没有到达屏障（即`bstate.nthread < nthread`），则当前线程会被阻塞，并释放互斥锁，等待其他线程到达屏障。这是通过`pthread_cond_wait(&bstate.barrier_cond, &bstate.barrier_mutex);`实现的。

      - 如果所有线程都到达屏障（即`bstate.nthread`等于线程总数`nthread`），则进行下一步。

   4. **开始新一轮的屏障**：当所有线程都到达屏障时，通过`bstate.round++;`增加`bstate.round`的值，表示新一轮的屏障开始。

   5. **重置线程计数**：通过`bstate.nthread = 0;`将线程计数`bstate.nthread`重置为0。

   6. **唤醒所有在屏障处等待的线程**：通过`pthread_cond_broadcast(&bstate.barrier_cond);`唤醒所有在屏障处等待的线程，让它们继续执行。

   7. **释放互斥锁**：通过`pthread_mutex_unlock(&bstate.barrier_mutex);`释放互斥锁，允许其他线程访问共享资源`bstate`。

   这些步骤共同实现了一个线程屏障，确保所有线程都到达屏障后才能继续执行。

2. 使用  `make qemu`  在终端中测试运行该程序

2. 使用 `./grade-lab-thread` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

无

##### 4) 实验心得

在这个实验中，通过实现一个线程屏障，深入理解了多线程编程中的同步机制。线程屏障是一种常见的同步手段，它可以确保所有线程在继续执行之前都达到某个点。这在需要所有线程同时开始执行某个任务，或者在所有线程都完成某个任务后才能进行下一步操作的场景中非常有用。

### Lab 7: networking

#### 1. Your Job (hard)

##### 1) 实验目的

通过为网络接口卡（NIC）编写一个xv6设备驱动程序，理解网络通信的核心机制。这包括创建以太网驱动程序，处理ARP请求和响应，实现IP数据包的发送和接收，处理ICMP Echo请求和响应，实现UDP数据报的发送和接收，以及实现一个简单的DHCP客户端以从DHCP服务器获取IP地址。通过这个实验，将深入理解网络协议栈的工作原理。

##### 2) 实验步骤

1. 首先切换到相应的分支：

   ```bash
   git fetch
   git checkout net
   make clean
   ```

2. 参照提示在kernel/e1000.c中完成`e1000_transmit()`和`e1000_recv()`，以便驱动程序可以发送和接收数据包：

   - 声明两个锁：

        ```c
        struct spinlock e1000_txlock;
        struct spinlock e1000_rxlock;
        ```

   - 用于传输数据包的函数为 `int e1000_transmit(struct mbuf *m)` ，其由驱动程序主动调用来传输数据包，其实现如下：

        - 首先，通过读取`E1000_TDT`控制寄存器，向E1000询问等待下一个数据包的TX环索引。
        
          ```c
              acquire(&e1000_txlock);
     	uint32 tail = regs[E1000_TDT];
        ```

      - 然后检查环是否溢出。如果`E1000_TXD_STAT_DD`未在`E1000_TDT`索引的描述符中设置，则E1000尚未完成先前相应的传输请求，因此返回错误。

        ```c
            if(!(tx_ring[tail].status & E1000_TXD_STAT_DD)){
                release(&e1000_txlock);
                return -1;
         }
        ```

      - 否则，使用`mbuffree()`释放从该描述符传输的最后一个`mbuf`（如果有）。
      
        ```c
            if(tx_mbufs[tail])
                    mbuffree(tx_mbufs[tail]);
        ```

      - 然后填写描述符。`m->head`指向内存中数据包的内容，`m->len`是数据包的长度。设置必要的cmd标志，并保存指向`mbuf`的指针，以便稍后释放。

        ```C
            tx_ring[tail].addr = (uint64)m->head;
            tx_ring[tail].length = (uint16)m->len;
            tx_ring[tail].cmd = E1000_TXD_CMD_RS | E1000_TXD_CMD_EOP;
         tx_mbufs[tail] = m;
        ```

      - 最后，通过将一加到`E1000_TDT`再对`TX_RING_SIZE`取模来更新环位置。
      
        ```c
            regs[E1000_TDT] = (tail+1) % TX_RING_SIZE;
        	release(&e1000_txlock);
        ```

      - 如果`e1000_transmit()`成功地将`mbuf`添加到环中，则返回0。如果失败（例如，没有可用的描述符来传输`mbuf`），则返回-1，以便调用方知道应该释放`mbuf`。（在第二步中有实现）

   - 用于接受数据的函数为 `static void e1000_recv(void)`。当操作系统接受到数据包时，其将产生设备中断并在 `devintr` 中调用 `e1000_intr` ，该函数调用 `e1000_recv` 完成对数据包的具体接受工作，其实现如下：

        - 首先通过提取`E1000_RDT`控制寄存器并加一对`RX_RING_SIZE`取模，向E1000询问下一个等待接收数据包（如果有）所在的环索引。
        
          ```c
              struct mbuf *newmbuf;
         acquire(&e1000_rxlock);
            uint32 tail = regs[E1000_RDT];
         uint32 curr = (tail + 1) % RX_RING_SIZE;
        ```

      - 然后通过检查描述符`status`部分中的`E1000_RXD_STAT_DD`位来检查新数据包是否可用。如果不可用，请停止。
      
        ```c
          if(!(rx_ring[curr].status & E1000_RXD_STAT_DD))
           break;
        ```

      - 否则，将`mbuf`的`m->len`更新为描述符中报告的长度。使用`net_rx()`将`mbuf`传送到网络栈。
      
        ```c
                rx_mbufs[curr]->len = rx_ring[curr].length;
                net_rx(rx_mbufs[curr]);
                tail = curr;
     ```
      
   - 然后使用`mbufalloc()`分配一个新的`mbuf`，以替换刚刚给`net_rx()`的`mbuf`。将其数据指针（`m->head`）编程到描述符中。将描述符的状态位清除为零。
      
        ```c
                newmbuf = mbufalloc(0);
                rx_mbufs[curr] = newmbuf;
             rx_ring[curr].addr = (uint64)newmbuf->head;
                rx_ring[curr].status = 0;
             regs[E1000_RDT] = curr;
                curr = (curr + 1) % RX_RING_SIZE;
        ```
      
      - 最后，将`E1000_RDT`寄存器更新为最后处理的环描述符的索引。
      
        ```c
         regs[E1000_RDT] = tail;
            release(&e1000_rxlock);
     ```

3. 使用  `make qemu`  在终端中测试运行该程序

2. 使用 `./grade-lab-net` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：E1000硬件的数据包接受与传输机制**

   为了完成本实验，我们必须要了解E1000硬件的数据包接受与传输机制。

      **解决方案**：查阅提供的”E1000 Software Developer's Manual” + 查看kernel/e1000_dev.h中相应的实现。

      在软件层面上，E1000的接受和传输主要都是基于一种名为**描述符**（descriptor）的数据结构完成的。描述符就像是一个信息中心，它包含了关于网络数据包的所有重要信息，包括数据的存储位置（地址）、数据的大小（长度）、数据的完整性信息（校验和）、描述符的当前状态以及可能的错误信息。通过读取和修改描述符，硬件和软件可以共享数据，进行有效的通信。

   1. 地址（addr）：这是描述符数据缓冲区的地址。这个地址是在内存中的位置，它指向的地方是硬件将数据（在这个情况下是网络数据包）直接存储的地方。
   2. 长度（length）：这是已经通过DMA（直接内存访问）传输到数据缓冲区的数据的长度。这告诉我们数据包有多大。
   3. 校验和（csum）：这是数据包的校验和。校验和是一种检查数据是否在传输过程中被更改的方法。如果数据在传输过程中被更改，那么校验和也会改变，这样我们就知道数据可能已经被破坏。
   4. 状态（status）：这是描述符的状态。它告诉我们描述符（以及相关的数据包）的当前状态。例如，它可能会告诉我们数据包是否已经被硬件接收。
   5. 错误（errors）：这是描述符的错误信息。如果在处理数据包时发生错误，这个字段就会包含相关的错误信息。
   6. 特殊（special）：这是一些特殊的信息，可能会被用于特定的情况。

##### 4) 实验心得

这次实验让我对网络编程有了更深入的理解。通过实现一个基本的网络协议栈，我理解了网络通信的核心机制，包括创建以太网驱动程序，处理ARP请求和响应，实现IP数据包的发送和接收，处理ICMP Echo请求和响应，实现UDP数据报的发送和接收，以及实现一个简单的DHCP客户端以从DHCP服务器获取IP地址。

在实现这些功能的过程中，我遇到了一些挑战，比如理解E1000硬件的数据包接受与传输机制，以及理解描述符和描述符环的概念。但是，通过查阅相关资料和反复调试，我最终成功地完成了这些任务。

这次实验也让我对操作系统如何处理网络通信有了更深入的理解。我了解到，操作系统不仅仅是管理硬件和运行应用程序，它还需要处理复杂的网络通信。这让我对操作系统的复杂性和强大性有了更深入的理解。

总的来说，这次实验虽然有一定的难度，但是它提供了一个很好的机会，让我能够深入理解网络通信的核心机制。我相信这次实验的经验将对我未来的学习和研究大有帮助。

### Lab 8: locks

> 在并发编程中，锁常被用于解决同步与互斥问题，但在多核机器上，若使用锁的方式不当，会引发许多称为“锁竞争”（lock contention）的问题。本实验的目标便是修改涉及锁的数据结构，以减少锁的竞争情况。

#### 1. Memory allocator (moderate)

##### 1) 实验目的

实现每个CPU的空闲列表，并在CPU的空闲列表为空时进行窃取。

##### 2) 实验步骤

1. 首先切换到相应的分支：

   ```bash
   git fetch
   git checkout lock
   make clean
   ```

2. 在kernel/kalloc.c中，进行以下操作：

   1. 为每个CPU分配kmem：

         ```c
         struct {
           struct spinlock lock;
           struct run *freelist;
         } kmem[NCPU];
         ```

   1. 修改`kinit`以便对这些锁进行初始化，适应新的数据结构：

         ```c
         void
         kinit()
         {
           char lockname[10];
           for (int i = 0; i < NCPU; i++)
        {
          snprintf(lockname, 10, "kmem_CPU%d", i);
          initlock(&kmem[i].lock, lockname);
        }
        freerange(end, (void*)PHYSTOP);
      }
      ```
      
   1. 修改`kfree`以便对这些锁进行释放，适应新的数据结构，使用`push_off()`和`pop_off()`来关闭和打开中断，以便`cpuid()`能够正确获得当前CPU编号：

         ```c
           // 只有在中断关闭时调用函数cpuid返回当前的核心编号，并使用其结果才是安全的。
           // 使用push_off()和pop_off()来关闭和打开中断。
           push_off(); 
           int id = cpuid();
           acquire(&kmem[id].lock);
        r->next = kmem[id].freelist;
        kmem[id].freelist = r;
        release(&kmem[id].lock);
        pop_off();
      ```
      
   1. 修改`kalloc`以便对申请空间过程中的锁进行处理，其逻辑如下：

         - 关闭中断并获取当前CPU的ID。
         - 获取当前CPU的内存锁，尝试从当前CPU的freelist中取出一个空闲块并返回。如果当前CPU的freelist为空，进入下一步。
         - 开始遍历所有的CPU，尝试从其他CPU的freelist中"偷取"空闲块。具体过程包括：
           - 跳过当前CPU。
           - 获取其他CPU的内存锁并检查其freelist。如果freelist为空，释放该CPU的内存锁并尝试下一个CPU。
           - 如果其他CPU的freelist非空，偷取其最多1024个空闲块。然后更新两个CPU的freelist，断开偷取的空闲块与其后的空闲块的连接，最后释放其他CPU的内存锁。
      - 在成功偷取到内存后，再次尝试从当前CPU的freelist中取出一个空闲块并返回。如果freelist非空，更新freelist。
      - 释放当前CPU的内存锁，返回空闲块。如果成功分配到内存，使用memset初始化分配的内存块为特定的值。

2. 使用 `./grade-lab-lock` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：解决锁竞争**

   xv6将空闲的物理内存kmem组织成一个空闲链表kmem.freelist，同时用一个锁kmem.lock保护freelist，所有对kmem.freelist的访问都需要先取得锁，所以会产生很多竞争。

   **解决方案**：给每个CPU单独开一个freelist以及其对应的锁lock，这样只有同一CPU上的进程同时获取对应锁时才会产生竞争，其数据结构如下：

      ```C
      struct {
        struct spinlock lock;
        struct run *freelist;
      } kmem[NCPU];
      ```

   在编写过程中，查阅相关资料时，发现有一个相对复杂的问题是：当一个CPU的freelist为空时，需要向其他 CPU的`freelist`“借”空闲块，具体实现如下：

      - 当前CPU`freelist`不空：取出该空闲块，更新freelist，然后将其分配给请求内存的任务。
      - 当前CPU`freelist`为空：从其他CPU的freelist中"借用"空闲块。
        - 遍历所有CPU
        - 获取CPU的锁和freelist
        - 检查freelist是否为空
        - 从非空freelist里面借用空闲块

##### 4) 实验心得

这次实验让我更好地理解了操作系统中并发控制和内存管理的原理。我学习了如何通过为每个CPU独立分配空闲列表来降低锁的竞争，提高多处理器系统性能。同时，我也明白了在多处理器环境下，通过关闭和开启中断来保证数据安全的重要性。

总之，这次实验提升了我的编程技能，同时也让我对操作系统的内存管理有了更深入的理解。

#### 2. Buffer cache (hard)

##### 1) 实验目的

Buffer cache是xv6文件系统的一部分，它的作用是保存磁盘的一部分数据，减少磁盘操作的时间消耗。但这也导致所有进程（包括在不同CPU上的进程）都会共享这个数据结构。如果我们仅使用一个锁bcache.lock来保证对它修改的原子性，将会产生大量的竞争，这可能导致性能下降。本实验便是自己设计来解决这个问题。

##### 2) 实验步骤

1. 在kernel/bio.c中进行如下操作：

   - 定义buckets数量（可以使用固定数量的散列桶，而不动态调整哈希表的大小。使用素数个存储桶（例如13）来降低散列冲突的可能性。）：

     ```C
     #define NBUCKET 13
     ```

   - 修改定义`bcache`

   - 定义哈希函数，以便更快找到对应的桶：

     ```c
     int hash(uint blockNo){
       return blockNo % NBUCKET;
     }
     ```

   - 需要修改`binit()`函数：初始化每个桶的锁和双向链表。每个桶都有一个自己的锁，用于在多线程环境中保护该桶的数据。每个桶也有一个双向链表，用于存储该桶中的所有缓冲区。 

   - 修改`bget()`函数：首先计算块号的哈希值，然后在对应的桶中查找是否已经有这个块的缓冲区。如果有，就直接返回这个缓冲区。如果没有，就从其他桶中找一个未使用的缓冲区，将其移动到当前桶中，并设置为需要的块。用`&bcache.hashlock[hashcode]`来替换`&bcache.lock`
   
   - 修改`breles`函数：减少缓冲区的引用计数。如果引用计数变为 0，说明没有进程正在使用这个缓冲区，将其移动到链表的头部，表示这个缓冲区是最近最少使用的。用`bcache.head[hashcode]`来替换`bcache.head`，用`&bcache.hashlock[hashcode]`来替换`&bcache.lock`即可

##### 3) 实验中遇到的问题和解决办法

1. **问题一：Buffer Cache的原子性修改**

   如果只用一个锁 bcache.lock保证对其修改的原子性的话，势必会造成很多的竞争。

   **解决方案**：根据数据块的blocknumber将其保存进一个哈希表，而哈希表的每个bucket都有一个相应的锁来保护，这样竞争只会发生在两个进程同时访问同一个bucket内的block。bcache的数据结构如下，之后需要对使用到其的地方进行修改。

##### 4) 实验心得

这个实验的目标是优化 xv6 操作系统的缓冲区缓存。主要方法是引入哈希表，将缓冲区分配到不同的哈希桶中，每个桶有自己的锁，减少锁的竞争，提高性能。同时，使用双向链表管理缓冲区，实现 LRU（最近最少使用）策略。这个实验有助于理解操作系统的缓冲区管理和数据结构性能优化。

### Lab 9: file system

> 本实验的主要目的是：向xv6文件系统添加大型文件和符号链接。

#### 1. Large files (moderate)

##### 1) 实验目的

增加xv6文件的最大大小，将一个直接数据块号替换成一个两层间接数据块号，即指向一个包含间接数据块号的数据块。

##### 2) 实验步骤

1. 首先切换到相应的分支：

   ```bash
   git fetch
   git checkout fs
   make clean
   ```

2. 修改kernel/fs.h中宏定义，如下：

   `NDIRECT`：这是直接指向数据块的地址数量；`NINDIRECT`：这是一个间接块可以包含的地址数量；`NDINDIRECT`：这是一个二级间接块可以包含的地址数量；`MAXFILE`：这是一个文件可以包含的最大数据块数量。

3. 修改dinode和inode结构：这一步在`dinode`和`inode`结构中增加了一个地址字段，用于存储二级间接块的地址。这样做的目的是为了能够访问更多的数据块。（`inode`在kernel/file.h中）即将`uint addrs[NDIRECT+1]`变为`uint addrs[NDIRECT+2]`。

4. 修改kernel/fs.c中的`bmap()`与`itrunc()`函数，使其能够处理二级间接块，实现逻辑如下：

   - 补充二级页表的寻找（仿照第一级的写法来写）：
        检查块号`bn`是否在二级间接块的范围内。如果是，它会进行以下操作：
        
        1. 检查二级间接块的地址是否已经存在。如果不存在，它会分配一个新的块，并将地址存储在`ip->addrs[NDIRECT + 1]`中。
        2. 使用`bread()`函数读取二级间接块的内容，并将其转换为一个整数数组`a`。
        3. 检查`bn / NINDIRECT`索引处的地址是否存在。如果不存在，它会分配一个新的块，并将地址存储在`a[bn / NINDIRECT]`中。然后，它会使用`log_write()`函数将修改写入日志。
        4. 释放对二级间接块的引用。
        5. 使用`bread()`函数读取`bn / NINDIRECT`索引处的块的内容，并将其转换为一个整数数组`a`。
        6. 检查`bn % NINDIRECT`索引处的地址是否存在。如果不存在，它会分配一个新的块，并将地址存储在`a[bn % NINDIRECT]`中。然后，它会使用`log_write()`函数将修改写入日志。
        7. 释放对`bn / NINDIRECT`索引处的块的引用。
        8. 返回`bn % NINDIRECT`索引处的块的地址。
      9. 如果`bn`不在二级间接块的范围内，它会触发一个panic，表示块号超出了范围。
      
   - 补充二级页表的块的释放（仿照第一级的写法来写）：
        
        1. 检查`ip->addrs[NDIRECT+1]`是否存在，如果不存在，说明没有二级索引，直接跳过。
        
        2. 使用`bread()`函数读取二级索引块到缓冲区`bp`，然后将`bp->data`转换为`uint`指针`a`。
        
        3. 遍历二级索引块中的所有一级索引块地址`a[j]`，如果`a[j]`存在，执行以下步骤：
           
           * 使用`bread()`函数读取一级索引块到缓冲区`d_bp`，然后将`d_bp->data`转换为`uint`指针`d_a`。
           
           - 遍历一级索引块中的所有数据块地址`d_a[i]`，如果`d_a[i]`存在，使用`bfree()`函数释放这个数据块。
         
         - 使用`brelse()`函数释放一级索引块的缓冲区`d_bp`，然后使用`bfree()`函数释放一级索引块。
         
         - 将一级索引块地址`a[j]`设置为0，表示这个一级索引块已经被释放。
         
      4. 使用`brelse()`函数释放二级索引块的缓冲区`bp`，然后使用`bfree()`函数释放二级索引块。
      
      5. 将二级索引块地址`ip->addrs[NDIRECT+1]`设置为0，表示这个二级索引块已经被释放。

##### 3) 实验中遇到的问题和解决办法

1. **bread()和brelse()的使用**

   在实验指南里有提到“别忘了把你`bread()`的每一个块都`brelse()`”为什么？

   **解决方案**：查阅资料，发现`bread()`和`brelse()`是xv6文件系统中用于操作缓冲区的两个函数：

   - `bread()`：这个函数的作用是读取一个块到缓冲区。它接受两个参数：设备号和块号。首先，它会在缓冲区中查找这个块。如果找到了，就直接返回这个块。如果没有找到，就分配一个新的缓冲区，从磁盘中读取这个块的内容到缓冲区，然后返回这个缓冲区。这个函数的主要作用是减少磁盘I/O操作，因为如果一个块已经在缓冲区中，就不需要再从磁盘中读取。
   - `brelse()`：这个函数的作用是释放一个缓冲区。它接受一个参数：一个缓冲区。首先，它会检查这个缓冲区是否被其他进程使用。如果没有，就将这个缓冲区放回到空闲列表。如果有，就等待其他进程释放这个缓冲区。这个函数的主要作用是管理缓冲区的使用，确保每个缓冲区在同一时间只被一个进程使用。

   在使用`bread()`读取一个块到缓冲区后，一定要记得使用`brelse()`释放这个缓冲区。因为如果不释放，这个缓冲区就会一直被占用，其他需要这个块的进程就无法获取到这个块，可能会导致死锁。

##### 4) 实验心得

在这次的实验中，我深入理解了xv6文件系统中的数据块管理方式，特别是如何通过一级和二级间接块来扩展文件的最大大小。我学习了如何修改文件系统的数据结构和相关函数，以支持二级间接块的使用。在实验过程中，我遇到了一些问题，比如如何正确使用`bread()`和`brelse()`函数，通过查阅资料和实践，我解决了这些问题。

总的来说，这次实验提升了我对文件系统和操作系统设计的理解，也锻炼了我的编程和问题解决能力。

#### 2. Symbolic links (moderate)

##### 1) 实验目的

常见的硬链接（例如A链接到B），会将A的inode号设置成和B文件一样，并且将对应inode的ref加一。而所谓符号链接（软链接），并不会影响B的inode，而是将A标记成特殊的软链接文件，之后对A进行的所有文件操作，操作系统都会转换到对B的操作，类似于一个快捷方式。在本练习中，将向xv6添加符号链接。

##### 2) 实验步骤

1. 为`symlink`创建一个新的系统调用号，在user/usys.pl、user/user.h中添加一个条目（同Lab2），向kernel/stat.h添加新的文件类型（`T_SYMLINK`）以表示符号链接。在kernel/fcntl.h中添加一个新标志（`O_NOFOLLOW`），该标志可用于`open`系统调用。

2. 在kernel/sysfile.c中实现的`sys_symlink`：

   1. 首先，函数获取两个参数：目标路径`target`和符号链接的路径`path`。这两个参数都是字符串，分别存储在`target`和`path`数组中。
   2. 然后，开始一个新的文件系统操作，保证文件系统的一致性。
   3. 接着，函数调用`create()`函数来创建一个新的符号链接。`create()`函数的参数包括路径、文件类型（这里是`T_SYMLINK`，表示符号链接）、主设备号和次设备号。`create()`函数返回一个指向新创建的inode的指针。
   4. 如果创建失败，函数会结束文件系统操作，并返回错误。
   5. 如果创建成功，函数会调用`writei()`函数将目标路径写入到新创建的符号链接的数据块中。`writei()`函数的参数包括inode指针、写入的数据、偏移量和写入的数据长度。
   6. 如果写入失败，函数会结束文件系统操作，并返回错误。
   7. 如果写入成功，函数会调用`iunlockput()`函数解锁并释放inode，然后结束文件系统操作。
   8. 最后，函数返回0，表示操作成功。
3. 在kernel/sysfile.c中，修改`sys_open`，设置最大搜索深度为10，如果到达10次，则说明打开文件失败。
3. 使用 `./grade-lab-fs` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：`begin_op()`与`end_op()`的使用方法**

   **解决方案**：查阅资料，总结如下：

   `begin_op()`和`end_op()`是xv6文件系统中用于同步文件系统操作的函数。在进行文件系统操作时，为了保证文件系统的一致性和防止数据竞争，需要使用这两个函数来包围文件系统操作。

   - `begin_op()`: 这个函数的主要作用是开始一个新的文件系统操作。在开始操作之前，它会检查文件系统是否处于安全状态。如果不是，它会等待直到文件系统变为安全状态。然后，它会增加正在进行的操作的数量，并返回。
   - `end_op()`: 这个函数的主要作用是结束一个文件系统操作。它会减少正在进行的操作的数量，然后检查是否有其他进程正在等待进行文件系统操作。如果有，它会唤醒这些进程。

   在使用时，需要注意以下几点：

   1. 每次调用`begin_op()`后，都必须调用`end_op()`来结束操作。否则，其他进程可能会无法进行文件系统操作。
   2. `begin_op()`和`end_op()`必须在同一层次的代码块中调用。也就是说，不能在一个函数中调用`begin_op()`，然后在另一个函数中调用`end_op()`。
   3. 在调用`begin_op()`和`end_op()`包围的代码块中，不应该有可能导致进程阻塞的操作。否则，可能会导致其他进程无法进行文件系统操作。
   4. 在调用`begin_op()`和`end_op()`包围的代码块中，应该尽量减少操作的时间，以减少对其他进程的影响。

   简而言之，与磁盘交互时调用系统调用都得先用这两句，只有执行成功和roll back，没有执行一半的说法。

##### 4) 实验心得

在这个实验中，我学习了如何在xv6操作系统中实现符号链接，这是一个非常重要的文件系统功能。我理解了`begin_op()`和`end_op()`的使用方法，这两个函数是xv6文件系统中用于同步文件系统操作的关键函数。总的来说，这个实验提供了一个很好的机会，让我深入理解文件系统的工作原理，以及如何在操作系统中实现复杂的文件系统功能。

### Lab 10: mmap

#### 1. Your Job (hard)

##### 1) 实验目的

`mmap`和`munmap`系统调用允许UNIX程序对其地址空间进行详细控制。它们可用于在进程之间共享内存，将文件映射到进程地址空间，并作为用户级页面错误方案的一部分。在本实验中，重点关注内存映射文件（memory-mapped files）。

##### 2) 实验步骤

1. 首先切换到相应的分支：

   ```bash
   git fetch
   git checkout fs
   make clean
   ```

2. 将程序以`$U/_mmaptest\`的形式，添加到Makefile的UPROGS中

3. 同Lab2修改相应文件

4. 在kernel/proc.h定义VMA（虚拟内存区域）对应的结构体，记录`mmap`创建的虚拟内存范围的地址、长度、权限、文件。由于xv6内核中没有内存分配器，因此可以声明一个固定大小的VMA数组，并根据需要从该数组进行分配,并将进程的vma结构体数组 `struct vma vma[VMASIZE] `添加到结构体`proc`中

5. 接下来修改`usertrap`，惰性地填写页表，以响应page fault。即`mmap`不应该分配物理内存或读取文件，通常发生在延迟加载（lazy loading）或者内存映射文件（memory-mapped file）的上下文中，逻辑如下：

      - 首先，检查引发页错误的虚拟地址（`va`）是否有效。如果虚拟地址超出了进程的地址空间，或者与进程的堆栈重叠，那么进程将被标记为需要被杀死。
      - 然后，遍历进程的虚拟内存区域VMA，寻找包含这个虚拟地址的区域。如果找到了包含这个虚拟地址的VMA，那么将为这个地址分配一块新的物理内存，并将这块内存清零。
      - 接下来，从VMA关联的文件中`readi`读取数据到新分配的物理内存中。
      - 然后，根据VMA的权限设置页表项的权限。例如，如果VMA标记为可写，那么页表项也会被标记为可写。
      - 最后，更新页表，将虚拟地址`mappages`映射到新分配的物理内存。如果这个步骤失败（例如，因为内存不足），那么新分配的物理内存将被释放，进程将被标记为需要被杀死。

6. 在kernel/sysfile.c中实现函数`sys_mmap()`：在进程的地址空间中找到一个未使用的区域来映射文件，并将VMA添加到进程的映射区域表中。VMA应该包含指向映射文件对应`struct file`的指针；`mmap`应该增加文件的引用计数，以便在文件关闭时结构体不会消失（参考`filedup`）：

      - `argaddr` `argint` `argfd`获取系统调用的参数，包括映射的起始地址、长度、权限、标志、文件描述符和偏移量。
      - 检查文件的写权限是否与映射的权限匹配。如果文件不可写，但映射需要写权限，且映射类型为共享映射，那么返回错误。
      - 检查映射的长度是否会导致进程的虚拟内存空间超过最大限制(`p->sz > MAXVA - length`)。如果会，那么返回错误。
      - 遍历进程的虚拟内存区域（VMA）数组，找到一个未使用的区域。
      - 在找到的VMA中设置映射的信息，包括地址、长度、文件、权限、标志、文件描述符和偏移量。
      - 调用`filedup()`函数增加文件的引用计数。这是因为现在有一个新的引用（即VMA）指向这个文件，所以需要增加引用计数，防止文件在还有引用的情况下被关闭。
      - 更新进程的虚拟内存空间大小，并返回映射的起始地址。

7. 在kernel/sysfile.c中实现函数`sys_munmap()`：找到地址范围的VMA并取消映射指定页面（使用`uvmunmap`）。如果`munmap`删除了先前`mmap`的所有页面，它应该减少相应`struct file`的引用计数。如果未映射的页面已被修改，并且文件已映射到`MAP_SHARED`，将页面写回该文件。查看`filewrite`以获得灵感:

      - 获取系统调用的参数，包括需要取消映射的起始地址和长度。
      - 将地址和长度分别向下和向上取整到页的边界，因为内存管理是以页为单位的。
      - 遍历进程的虚拟内存区域（VMA）数组，找到包含需要取消映射地址的区域。
      - 如果没有找到满足条件的VMA，那么直接返回。
      - 如果找到了满足条件的VMA，那么检查VMA的起始地址是否等于需要取消映射的地址。如果等于，那么进行以下操作：
        - 更新VMA的起始地址和长度，将取消映射的部分从VMA中移除。
        - 如果VMA的映射类型是共享映射，那么调用`filewrite()`函数将脏页的内容写回到文件。脏页是指被修改过的页，需要写回到文件以保证数据的一致性。
        - 调用`uvmunmap()`函数取消页表的映射。这个函数的参数包括页表、起始地址、页数和是否释放物理内存。这里设置为1，表示释放物理内存。
        - 如果VMA的长度变为0，那么关闭文件，将VMA标记为无效。
      - 最后，函数返回0，表示操作成功。

8. 修改kernel/vm.c中的uvmcopy和uvmunmap，避免因不合法而panic

9. 在kernel/proc.c中修改`exit`将进程的已映射区域取消映射，就像调用了`munmap`一样

10. 在kernel/proc.c中修改`fork`以确保子对象具有与父对象相同的映射区域

2. 使用 `./grade-lab-mmap` 进行该实验的测试和评分

##### 3) 实验中遇到的问题和解决办法

1. **问题一：VMA结构体的设计**

   **解决方案**：提示中有如下，结合资料对于其的设计如下。

   定义VMA（虚拟内存区域）对应的结构体，记录`mmap`创建的虚拟内存范围的地址、长度、权限、文件。

   1. `valid`：有效位，用于标记这个VMA是否正在使用。如果为1，表示该VMA正在使用；如果为0，表示该VMA没有被使用。
   2. `addr`：VMA的起始地址。在xv6中，可以假设地址始终为0。
   3. `length`：VMA映射的字节数。它表示了VMA的大小。
   4. `f`：一个指向`file`结构体的指针，表示该VMA对应的被映射的文件。
   5. `prot`：VMA的保护位，用于标记这个内存区域是否应该被映射为可读或可写。
   6. `flags`：该VMA的标志位，表示该映射是共享的（`MAP_SHARED`）还是私有的（`MAP_PRIVATE`）。
   7. `fd`：这是这个VMA对应的文件的文件描述符。
   8. `offset`：这是这个VMA在文件中的偏移量。在xv6中，可以假设这个偏移量始终为0。

##### 4) 实验心得

在本实验中，将`mmap`和`munmap`系统调用添加到了xv6操作系统中，并重点关注了内存映射文件。通过实现相关函数和修改相应的文件，我成功地实现了在进程地址空间中映射文件，并能够根据权限和标志来控制映射的行为。

实验中遇到的问题主要是对VMA结构体的设计和使用，需要仔细理解VMA的作用和每个成员的含义，以确保正确地进行内存映射和取消映射的操作。

通过完成这个实验，我对`mmap`和`munmap`系统调用有了更深入的理解，并学会了在操作系统中实现内存映射文件的功能。这对于进程间共享内存、延迟加载和垃圾收集等方面都非常有用。同时，实验也增强了我对操作系统内存管理和文件系统的理解。

### 我的仓库地址

git地址：https://github.com/Guaaaava/OS-xv6-labs-2021.git

网页地址：https://github.com/Guaaaava/OS-xv6-labs-2021
